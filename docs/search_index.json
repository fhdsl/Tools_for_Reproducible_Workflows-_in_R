[["index.html", "Tools for Reproducible Workflows in R About this Course 0.1 Available course formats", " Tools for Reproducible Workflows in R March, 2023 About this Course Reproducibility of data analyses can be enhanced through the use of tools designed to manage the complexity involved in any data analysis designed to address an important scientific question. We focus on a few software tools that aid in project organization, collaboration, auditability of analyses, and maintaining the integrity of data and code. In this course, we view a data analysis as a complex system with many integrated parts that together produce analytic results. The tools we focus on here allow data analysts to diagnose unexpected results, quickly identify problems with data and code, and provide a basis for managing the dynamic nature of data analysis. This initiative is funded by the following grant: R25GM141505 from the National Institute of General Medical Sciences (NIGMS). Except where otherwise indicated, the contents of this course are available for use under the Creative Commons Attribution 4.0 license. You are free to adapt and share the work, but you must give appropriate credit, provide a link to the license, and indicate if changes were made. Sample attribution: Tools for Reproducible Workflows in R by Fred Hutchinson Data Science Lab and University of Texas, Austin (CC-BY 4.0). You can download the illustrations by clicking here. 0.1 Available course formats This course is available in multiple formats which allows you to take it in the way that best suites your needs. You can take it for certificate which can be for free or fee. The material for this course can be viewed without login requirement on this Bookdown website. This format might be most appropriate for you if you rely on screen-reader technology. This course can be taken for free certification through Leanpub. This course can be taken on Coursera for certification here (but it is not available for free on Coursera). Our courses are open source, you can find the source material for this course on GitHub. "],["introduction.html", "Chapter 1 Introduction 1.1 Motivation 1.2 Target Audience 1.3 Curriculum 1.4 Learning Objectives", " Chapter 1 Introduction In this course we will explore a variety of tools that can assist with data analysis from a broad range of fields. The tools we will cover may take some time to get used to, but the payoff will be immeasurable. Not only are these skills valuable for career advancement, they will also make your work-life easier. The tools will enhance your ability to reproduce your work across similar projects, stay organized, collaborate with others effectively, and more. 1.1 Motivation Many researchers are self-taught when it comes to computer science. However, data analysis has become a requirement for most researchers. The ability to smoothly work in a reproducible manner not only makes for easier more maintainable workflows, it also improves scientific rigor and transparency. This course will help learners to use tools that will make their data analytic workflows more organized, more understandable to collaborators (and your future self!), and ultimately more efficient. 1.2 Target Audience This course is intended for people conducting data analyses at the level of a graduate student or higher. The course is designed so that the majority of the material is presented in a high-level manner that should be applicable to researchers working in a broad range of areas. The course is centered around the R programming language, a widely used statistical analysis software package. 1.3 Curriculum The course covers… 1.4 Learning Objectives Implement basic project organization tools: R Studio tips and tricks for efficiency R Markdown to create reports Setup and configure RStudio/RStudio projects for data analysis (here package and file structure/paths) Install and configure ProjectTemplate package for formalizing and automating workflows Apply the pointblank package for validation of tabular data Write functions and package them Apply the testthat package for building software unit tests Setup and use Git repositories for version control of code Interface with GitHub to share Git repositories for collaboration; execute GitHub-based workflows Pull Requests Code review Issues Discussions References will include Gillespie and Lovelace (2021), Riederer (2020), Timbers, Campbell, and Lee (2022). Code review references will include “About Scientific Code Review” (n.d.), Radigan (n.d.), Parker (2017), Bodner (2018). "],["r-for-reproducibility.html", "Chapter 2 R for Reproducibility 2.1 Learning Objectives 2.2 Why R 2.3 It is free and open source 2.4 The community 2.5 Designed for data 2.6 Conclusion", " Chapter 2 R for Reproducibility 2.1 Learning Objectives Before we begin to jump into additional tools that R can help us with to be work more efficiently and in a more reproducible manner, it is helpful to first discuss why we should consider R in the first place. After completing this section you will be able to: 2.2 Why R R is a programming language for working with data, performing statistical analyses, and for creating plots and graphics that was developed in 1991 by Ross Ihaka and Robert Gentleman at the University of Auckland, New Zealand (“R (Programming Language)” 2023; “R: The R Project for Statistical Computing”). Countless contributors have made R what it is today. There are some especially useful aspects about R that make it a great option for creating reproducible data analyses. 2.3 It is free and open source The first is that R is free and open source. The term open source means that the code is publicly available. Thus all of the code involved in creating R is actually publicly available! This enables users to check what code is used in a particular package (a set of code that allows you to do various things) so that they can modify or build upon the code if they would like to. In fact, many users create their own R packages to share their code with others. There are places such as the Comprehensive R Archive Network (CRAN) and elsewhere that allow users to publish their own packages for others to use. programming language - A specified set of notations to tell a computer what to do R - Programming language for working with data to perform statistical analyses and for creating plots and other graphics open source - Code is publicly available R package - A set of code that can be shared between users Why are these aspects good for reproducibility? Since R is free, it is accessible to anyone. Therefore, anyone could run your code if you shared it with them, without them needing to buy software. Since R is open source, if you use packages from others, people can determine what underlying code your code used (if you tell them what version you used - more on that later!) 2.4 The community R has a very rich and active community! This makes it easier to reach out to others for help, find support, find tutorials, and more. There are several R community groups that are especially helpful: R Ladies - a support group that is not just for ladies, but is open to anyone who wants to improve their R skills! There are local chapters in many large cities that often have in-person meetings. There are lots of useful resources, such as the R for Data Science book (written by two developers at Posit (formally called RStudio) which develops lots of core R packages), resources and online courses from the Johns Hopkins Data Science Lab including Open Case Studies, resources and workshops from Data Carpentry, Dataquest, DataTrail and more! See this link for more R resources. Why is this rich community good for reproducibility? Overall your code has a better chance of being more accessible than if it were written in a language that is not open source or that has limited support. You can also find support to make sure your code does what you want it to, as well as support to make your code as reproducible as possible. 2.5 Designed for data R is a statistical programming language, meaning it was designed to help you analyze data. It is the main focus of the language. This is one of the major advantages of using R over other programming languages that have more general purposes. Because of this many people have designed useful packages that are especially relevant to: Dealing with messy data in a systematic and reproducible way to get it into a state that is useful for data analysis Producing statistical analysis of data Creating effective plots of data Although other options like SPSS and SAS (which are not free!) can also be helpful for statistical analysis, R is especially powerful at getting messy data ready to analyze and for creating useful plots to represent patterns in data. Conveniently, R can do all of these steps in a data project and does not require users to switch between different programs to perform these tasks. R also helps create reports that can demonstrate to collaborators and others exactly how analysis was performed, aiding in the transparency of how the data was used from start to finish. R can also import data from many different sources that other statistical software can’t handle (including scraping data from websites or PDFs). This allows users much more flexibility to use data as close to the source as possible. This can enable users to stop copy and pasting data and reduce the risk of human error. If you are interested, see Open Case Studies for more guidance on importing many different kinds of data. Why are these design features especially helpful for creating reproducible analyses? It enables users to work with messy data and get it ready for analysis, as opposed to requiring users to use other programs. The tidyverse a suite of very helpful packages has many data wrangling packages that are especially intuitive for others to read and understand your code. Users can create effective plots using the same program as for data prep and analysis. The ggplot2 package is famous for making really effective and customizable plots. It helps create reports that can show the entire data analysis process from importing the data to making plots. R Markdown reports are very helpful for this. It is easier to import data closer to the original source, rather than converting files or copy and pasting data, which can result in accidental modifications of the data. 2.6 Conclusion In summary, R can be especially useful if you want to make your data analyses more transparent and reproducible for the following reasons: It is free and open source, meaning that code that you might incorporate in your analyses is accessible to anyone. Secondly, others can use your code without needing to buy software. There is a rich R community that can help you make the most out of your code and learn how to write your code in a more reproducible manner. R is particularly powerful for preparing data for analysis and for creating visual representations of data. Beyond being free, these unique benefits make R a particularly good statistical tool. R is especially designed to analyze data and for the entirety of the process, which makes it great for creating transparent information about how you actually worked with data from start to finish. "],["components-of-a-reproducible-analysis.html", "Chapter 3 Components of a reproducible analysis 3.1 Reproducibility is iterative work 3.2 Components of reproducibility 3.3 Transparent 3.4 Consistent 3.5 Accessible 3.6 Conclusion", " Chapter 3 Components of a reproducible analysis In this chapter, we will discuss what components of an analysis make it reproducible. 3.1 Reproducibility is iterative work Making an analysis isn’t something that happens on the first try. Working on a project iteratively and continuing to improve the reproducibility of it is the best approach. In this manner, we can view reproducibility on a continuum. Some projects are just run once but aren’t really needed anymore, and don’t become very polished or reproducible. But as we continue to work on a project and polish its reproducible components, it continues to be more perfected. However, because of the moving nature of some reproducibility components, no project is really perfectly reproducible in every context throughout time. 3.2 Components of reproducibility A reproducible analysis is transparent, consistent, and accessible. Transparency refers to the idea that it is well communicated and everything is displayed: data, code, goals, methods, and decisions. There are no secrets in a reproducible analysis/ Consistency refers to the idea that the code can be consistently run, but also everything follows a particular system, conventions and design. Accessibility refers to the idea that anyone anywhere should be able to run and/or examine the analysis. No pay walls or expensive software should be required. 3.3 Transparent One essential piece of a reproducible analysis is that the code runs reliably. However, to really make an analysis reproducible, the decisions made in the analysis should also be clearly communicated. A transparent analysis is not only well communicated, but also shared publicly in a way that others can comment and contribute ideas and suggestions to or borrow methods and strategies for their own analyses. 3.3.1 Open source Open source means not only making code and data publicly available, but also enabling others to modify or comment on the code. This doesn’t mean that any and all modifying contributions need to be accepted, because some level of standards and quality checks need to be maintained by the owners of the analysis, but just that anyone online could propose a contribution if they wanted to. For an analysis to be truly open source, it needs to be easily accessed by others and stored online. Code that can be emailed, for example, is not considered open source. For reproducibility, keeping your code on GitHub is a great open source solution. GitHub is a code hosting platform that allows people to access code and sometimes data. It is commonly used, and has a built in system that allows others to contribute changes in a way that can be methodically reviewed by you (this is called the pull request system and we will talk about it more). GitHub - An online platform for sharing and managing code and files in an open source manner 3.3.2 Data is publicly available A transparent analysis has data that is publicly shared so that others can re-run the analysis as you have. Data should be provided in a way that it can be programmatically accessed (downloaded by a script). Data also need to be well-documented in the form of metadata. Data sharing is a critical piece for promoting the open sourceness of your analysis, however this often needs to be balanced with privacy if you work with human data or samples. These data will likely contain personal identifiable information (PII) and protected health information (PHI). For more details on this, we encourage you to see this course about data management. While it’s imperative that you protect human data, that doesn’t mean that your analysis cannot be publicly shared! These are not mutually exclusive goals, but will take a bit of thoughtful planning. In the upcoming chapters we will provide additional ideas and information for how you can conduct an open source analysis while appropriately protecting sensitive data. 3.3.3 Readable code Readable code is much more important than clever code. If you are the only one who knows what your code is doing, it will not only be difficult for others to contribute or vet your analysis, but in the future, you will probably not understand what your code is doing either. Read this course chapter from the ITCR training network about how to write durable code. 3.3.4 Well-documented A well-documented analysis is a reproducible analysis. If analyses didn’t require a lot of decisions and human comprehension than documentation wouldn’t be necessary – but also a lot of data analysts would be out of a job because robots would be able to do it! Analysts and developers often think of documentation as an after-thought, but good documentation should be actively developed along with the code. Arguably, it is more important to have clear documentation than even working code, because if broken code is well-documented, others may be able to help make suggestions for how it can be fixed. Good documentation not only describes what happened in an analysis, but why it happened – why did the analyst choose this method or parameter as opposed to others? Was there an additional analysis, literature, or other resource that led us to this conclusion? Documentation should describe not only what is happening, but the thought process that led us here. 3.3.5 Version controlled A reproducible analysis is a version controlled analysis. Analyses go through many iterations, side quests, and occasional dead ends – and this is okay, it is how data science works! – but if not done properly with version control, this can lead to an unruly code base and a lot of confused team members. Version control is a method for tracking changes to files in a systematic manner. One such method of version control is called git and we will talk about how to use git and its online website GitHub, in a future chapter. Version control helps maintain the history of your project in a way that will allow you to recover old versions if necessary, or otherwise have documentation on what has happened. It can also be useful for rectifying different versions of a code base between team members. version control - A method of tracking and handling files as they are changed over the course of a project 3.4 Consistent A reproducible analysis is consistent. It should consistently run and consistently produce the same results. It should also be written in a manner that follows a consistent style and project organization scheme. 3.4.1 Re-runs consistently and easily Ideally, a reproducible analysis should be able to re-run with one command that is explicitly stated in a README file. This is a file that explains what all the rest of the files are and the point of the project. If an individual has a copy of the analysis project, it should include everything that is needed to re-run that analysis and the number of steps needed to re-run the analysis should be the lowest number possible. The more steps that are needed, the less likely it will be that someone will be able to reproduce the analysis. This also generally means that analyses that can be performed through programmatic scripts are more reproducible than those performed by GUI’s (graphic user interfaces). GUIs are programs on computers that are used by pointing and clicking buttons whereas command line programs are used by typing in commands. Command line programs generally take scripts that allow you to have each step written in the script which can be easily recalled to re-run the entire analysis. Most GUI’s, although sometimes more intuitive to use, are unfortunately less reproducible because they require more manual steps by clicking various buttons. GUI (graphic user interface) - A type of program on a computer that you use by pointing and clicking with a mouse Command line - A type of program on a computer that you use by typing in commands or writing scripts that can be run 3.4.2 Follows a code style Code style is important because it not only makes code more readable, but it also lends a certain confidence to the reader of the code, that this code has been thought through and perhaps polished more than code that is less consistent in its style. 3.4.3 Have an organizational scheme Project organization is a major component of reproducibility. If you are not able to find your files, then chances are individuals who are attempting to reproduce your analysis also will not be able to understand where to find things. We will discuss in a later chapter strategies for keeping projects organized, while realizing that project organization is an ongoing, dynamic task. 3.5 Accessible We discussed that we use R because it is open source and free. This makes it conducive for making reproducible analyses. Accessibility is important for reproducibility. This means minimizing the number of hoops others have to jump through to re-run your analysis. Accessibility also involves prioritizing democratizing science and enabling as many people as possible to understand what you did for your analyses. We encourage you to realize that science does best when everyone has access to it and that includes code and data analyses! Making your data and code accessible, allows everyone to contribute and learn from your analysis. Note that if you are concerned about being scooped, you can make your code private on GitHub while you are working on it and then make it public once you release a preprint of your results. We will talk more about this later. Accessibility means that anyone should be able to access it – whether or not their funding is in ample supply. So be sure to publish in code repositories that do not require membership fees or any other kinds of paywalls. Make an effort to publish in journals that are freely available as well. Sometimes even if something is accessible in that it is “free” monetarily it doesn’t mean that it is free in the sense of the amount of time it takes to access it. If your code and data does need some sort of controlled access features for privacy and ethical concerns of protecting data, make sure that the paperwork hoops that are put in place are truly there in the spirit of protecting the data and not instead to keep data and code hidden from others. 3.6 Conclusion In this chapter, we gave a high level overview of reproducible analyses. We discussed that reproducible analyses are transparent, consistent, and accessible. This means in practical terms, reproducible analyses: Are open source Have data that is publicly available (when appropriate) Have readable code Are well-documented Re-run easily Have an organizational scheme Follow a code style Do not have paywalls or other barriers (except for ethical or data privacy reasons) "],["a-tour-of-rstudio.html", "Chapter 4 A Tour of RStudio 4.1 Why use RStudio?", " Chapter 4 A Tour of RStudio In this chapter we will talk about a very useful R-related tool called RStudio. RStudio is an environment for using R that can be extremely helpful for writing code and making your analyses reproducible. 4.1 Why use RStudio? RStudio is what is called an integrated development environment(IDE) for writing code in R (although it also has compatibility for other languages). It is designed to make working in R easier in a variety of ways: it helps you write code by suggesting code based on what you have written - currently this is mostly for suggesting package names or functions (which are specific pieces of code that accomplish a particular task, often packages have several functions) it helps you view the output of your code in an easier manner, especially plots it helps you find errors in your code it helps you keep track of any objects that you have assigned in R it helps you orient yourself in terms of the files on your computer can be used to help track changes in your code and other files over time IDE - Integrated Development Environment - a computing environment for writing code, debugging code, and looking at the output of your code RStudio - an IDE designed especially for writing R code function - a specific piece of code that performs a task - packages in R often have several functions "],["setting-up-your-project.html", "Chapter 5 Setting up your project", " Chapter 5 Setting up your project "],["transparency-in-analyses.html", "Chapter 6 Transparency in Analyses", " Chapter 6 Transparency in Analyses "],["using-github-in-a-workflow.html", "Chapter 7 Using GitHub in a workflow", " Chapter 7 Using GitHub in a workflow "],["software-versions.html", "Chapter 8 Software versions 8.1 Learning Objectives 8.2 No two computers are the same 8.3 Software and package versions affect results! 8.4 Session Info 8.5 Snapshots with renv 8.6 Containerization 8.7 Conclusion", " Chapter 8 Software versions 8.1 Learning Objectives As we discussed, reproducibility is on a continuum, meaning that it can range from being impossible to very easy to reproduce any given results. Some results can be effectively impossible to reproduce if there are too many barriers and set up needed to re-run the analysis. One of the most common barriers is the computing environment used run the analysis. computing environment - All the relevant pieces of software and their dependencies that were used on a computer at the time that an analysis or other project was run 8.2 No two computers are the same A computing environment not only consists of the direct software that we use to analyze data, but all of the other software that our main pieces of software require to install and run properly. As we use our computers daily for work, we are constantly installing, updating, and removing software packages. Sometimes our computers do this automatically without us knowing. These software packages interact with and depend on each other, meaning it can be quite frustrating to try update even a single piece of software if it exists in a tangled mess of software dependencies. Computer scientists sometimes call this “dependency hell”. As developers and maintainers of software continue to make updates and fixes to the software, the developers and maintainers of other interdependent software are doing similarly, meaning that software dependencies and the computing environments are not only a complicated mess at times, but also a moving target! 8.3 Software and package versions affect results! Sometimes if we have generally the same software installed for reproducing an analysis, we may feel that that is “close enough”. And given all the other technical aspects of reproducibility, it can be easy to overlook what versions of software packages we are using. However, controlling for software versions is critical for creating reproducible analyses. Software versions can directly affect not only whether an analysis will be able to run, but the results of the analysis (Beaulieu-Jones and Greene 2017). 8.4 Session Info Perhaps the easiest way to begin to address computing environment variability is to record what the computing environment looks like at the time an analysis is run. In R, this is a fairly straightforward task. Generally at the end of your R notebook, you will want to print out your session info. You can do this by running the function sessionInfo() or the tidyverse version of this function from the devtools package, devtools::session_info(). We can run sessionInfo in this book (this book was created using R tools). sessionInfo() ## R version 4.0.2 (2020-06-22) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Ubuntu 20.04.5 LTS ## ## Matrix products: default ## BLAS: /usr/lib/x86_64-linux-gnu/openblas-pthread/libblas.so.3 ## LAPACK: /usr/lib/x86_64-linux-gnu/openblas-pthread/liblapack.so.3 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] knitr_1.33 magrittr_2.0.3 hms_0.5.3 R6_2.4.1 ## [5] rlang_1.0.6 fastmap_1.1.1 highr_0.8 httr_1.4.2 ## [9] stringr_1.4.0 tools_4.0.2 xfun_0.26 cli_3.6.0 ## [13] jquerylib_0.1.4 ellipsis_0.3.1 htmltools_0.5.4 ottrpal_1.0.1 ## [17] yaml_2.2.1 digest_0.6.25 tibble_3.0.3 lifecycle_1.0.3 ## [21] crayon_1.3.4 bookdown_0.24 readr_1.4.0 sass_0.4.5 ## [25] vctrs_0.5.2 fs_1.5.0 curl_4.3 cachem_1.0.7 ## [29] evaluate_0.20 rmarkdown_2.10 stringi_1.5.3 pillar_1.4.6 ## [33] compiler_4.0.2 bslib_0.4.2 jsonlite_1.7.1 pkgconfig_2.0.3 Now we have recorded what some key aspects of our computing environment looked like at the time that this book was rendered last. This print out may seem like a lot of nonsense at first, but it gives us some useful information in a pinch! If we take a look at two different session info printouts, we can begin to spot the differences. These differences may give us clues into why an analysis ran differently. Printing out session info is an easy way to record your computing environment in hopes of increasing the reproducibility of your analysis! session info - A printout in R that displays information about the software and packages that were being used at the time the sessionInfo() or devtools::session_info() functions were run. 8.5 Snapshots with renv However, you may realize that while session info is useful for recording this information, it doesn’t mitigate the frustration of setting up a computing environment in R. Nor does it help us with being able to directly share our computing environments. It can be incredibly handy for reproducibility purposes to be able to share the R computing environment you used for completing an analysis. This is not only helpful for others who may be interested in reproducing your analysis, but also for future you! If you come back to this analysis and attempt to re-run it, it is likely you’ve changed your R computing environment over time by installing or removing packages. renv will allow you to return to the environment you used at the time that you ran the analysis. For that, we need a slightly more involved solution of using renv. renv is an R package that allows you to take ‘snapshots’ of your R computing environment and use those to track, share, and build R environments. The renv workflow looks like this (as described by their documentation): Call renv::init() to initialize a new project-local environment with a private R library Work in the project as normal, installing and removing new R packages as they are needed in the project Call renv::snapshot() to save the state of the project library to the lockfile (called renv.lock) Continue working on your project, installing and updating R packages as needed Call renv::snapshot() again to save the state of your project library if your attempts to update R packages were successful, or call renv::restore() to revert to the previous state as encoded in the lockfile if your attempts to update packages introduced some new problems To make this shareable to others, you will need to do two things: Be sure to commit and push the renv.lock file to your GitHub repository for your project. Be sure to describe that your project uses renv in the README of this project (commit and push this to your GitHub repository also). The limitations of this method, as noted by the renv authors, is that it really only tracks packages in R and cannot help track or enforce items that may affect the computing environment outside of R. So while it will aid in the reproducibility of your analysis, it will not cover everything. renv - An R package that helps you to share and record your R specific computing environment 8.6 Containerization In order to truly reproduce a result with an identical computing environment you would need to use a containerized approach. To containerize a computing environment is to truly create an environment that is shippable to others. A container is analogous to a virtual machine. A computer runs a computing environment inside of it that is separate from the rest of the computer (hence why its called a container). One of the most popular containerization softwares is Docker. Docker allows you to build your computing environment and share it on its online platform in the form of images that you can download and run. In fact, this book is rendered by a Docker container! If you will be using a container with PHI or PII or other protected information, we recommend you take a look at this resource to understand best practices for using Docker with sensitive data. container - A method for running software in a way that is shareable and Reproducible Docker - A popular platform for containers We will not cover Docker here but if you are interested in using a containerized approach like Docker, here are additional resources for learning: Software Carpentries course on Docker ITCR Training Network chapters about Docker Docker documentation about getting started How to ensure your Docker usage is HIPAA-Compliant HIPAA Compliant Containers Singularity is a different container platform that does some encryption – this can help if you are using data that needs to be protected. 8.7 Conclusion In summary: Software versions affect the reproducibility of an analysis. Printing out session info is a great way to record software versions. renv is an R package that allows you to share your R specific computing environment. Containerization softwares like Docker allow you to more completely share a replicate computing environment. "],["sharing-data.html", "Chapter 9 Sharing Data", " Chapter 9 Sharing Data "],["functions.html", "Chapter 10 Functions", " Chapter 10 Functions "],["project-maintenance-and-updates.html", "Chapter 11 Project maintenance and updates", " Chapter 11 Project maintenance and updates "],["collaborations-through-github.html", "Chapter 12 Collaborations through GitHub", " Chapter 12 Collaborations through GitHub "],["about-the-authors.html", "About the Authors", " About the Authors These credits are based on our course contributors table guidelines.     Credits Names Pedagogy Lead Content Instructor(s) FirstName LastName Lecturer(s) (include chapter name/link in parentheses if only for specific chapters) - make new line if more than one chapter involved Delivered the course in some way - video or audio Content Author(s) (include chapter name/link in parentheses if only for specific chapters) - make new line if more than one chapter involved If any other authors besides lead instructor Content Contributor(s) (include section name/link in parentheses) - make new line if more than one section involved Wrote less than a chapter Content Editor(s)/Reviewer(s) Checked your content Content Director(s) Helped guide the content direction Content Consultants (include chapter name/link in parentheses or word “General”) - make new line if more than one chapter involved Gave high level advice on content Acknowledgments Gave small assistance to content but not to the level of consulting Production Content Publisher(s) Helped with publishing platform Content Publishing Reviewer(s) Reviewed overall content and aesthetics on publishing platform Technical Course Publishing Engineer(s) Helped with the code for the technical aspects related to the specific course generation Template Publishing Engineers Candace Savonen, Carrie Wright Publishing Maintenance Engineer Candace Savonen Technical Publishing Stylists Carrie Wright, Candace Savonen Package Developers (ottrpal) Candace Savonen, John Muschelli, Carrie Wright Art and Design Illustrator(s) Created graphics for the course Figure Artist(s) Created figures/plots for course Videographer(s) Filmed videos Videography Editor(s) Edited film Audiographer(s) Recorded audio Audiography Editor(s) Edited audio recordings Funding Funder(s) Institution/individual who funded course including grant number Funding Staff Staff members who help with funding   ## ─ Session info ─────────────────────────────────────────────────────────────── ## setting value ## version R version 4.0.2 (2020-06-22) ## os Ubuntu 20.04.5 LTS ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## ctype en_US.UTF-8 ## tz Etc/UTC ## date 2023-03-27 ## ## ─ Packages ─────────────────────────────────────────────────────────────────── ## package * version date lib source ## assertthat 0.2.1 2019-03-21 [1] RSPM (R 4.0.5) ## bookdown 0.24 2023-03-10 [1] Github (rstudio/bookdown@88bc4ea) ## bslib 0.4.2 2022-12-16 [1] CRAN (R 4.0.2) ## cachem 1.0.7 2023-02-24 [1] CRAN (R 4.0.2) ## callr 3.5.0 2020-10-08 [1] RSPM (R 4.0.2) ## cli 3.6.0 2023-01-09 [1] CRAN (R 4.0.2) ## crayon 1.3.4 2017-09-16 [1] RSPM (R 4.0.0) ## desc 1.2.0 2018-05-01 [1] RSPM (R 4.0.3) ## devtools 2.3.2 2020-09-18 [1] RSPM (R 4.0.3) ## digest 0.6.25 2020-02-23 [1] RSPM (R 4.0.0) ## ellipsis 0.3.1 2020-05-15 [1] RSPM (R 4.0.3) ## evaluate 0.20 2023-01-17 [1] CRAN (R 4.0.2) ## fastmap 1.1.1 2023-02-24 [1] CRAN (R 4.0.2) ## fs 1.5.0 2020-07-31 [1] RSPM (R 4.0.3) ## glue 1.4.2 2020-08-27 [1] RSPM (R 4.0.5) ## htmltools 0.5.4 2022-12-07 [1] CRAN (R 4.0.2) ## jquerylib 0.1.4 2021-04-26 [1] CRAN (R 4.0.2) ## jsonlite 1.7.1 2020-09-07 [1] RSPM (R 4.0.2) ## knitr 1.33 2023-03-10 [1] Github (yihui/knitr@a1052d1) ## magrittr 2.0.3 2022-03-30 [1] CRAN (R 4.0.2) ## memoise 2.0.1 2021-11-26 [1] CRAN (R 4.0.2) ## pkgbuild 1.1.0 2020-07-13 [1] RSPM (R 4.0.2) ## pkgload 1.1.0 2020-05-29 [1] RSPM (R 4.0.3) ## prettyunits 1.1.1 2020-01-24 [1] RSPM (R 4.0.3) ## processx 3.4.4 2020-09-03 [1] RSPM (R 4.0.2) ## ps 1.4.0 2020-10-07 [1] RSPM (R 4.0.2) ## R6 2.4.1 2019-11-12 [1] RSPM (R 4.0.0) ## remotes 2.2.0 2020-07-21 [1] RSPM (R 4.0.3) ## rlang 1.0.6 2022-09-24 [1] CRAN (R 4.0.2) ## rmarkdown 2.10 2023-03-10 [1] Github (rstudio/rmarkdown@02d3c25) ## rprojroot 2.0.3 2022-04-02 [1] CRAN (R 4.0.2) ## sass 0.4.5 2023-01-24 [1] CRAN (R 4.0.2) ## sessioninfo 1.1.1 2018-11-05 [1] RSPM (R 4.0.3) ## stringi 1.5.3 2020-09-09 [1] RSPM (R 4.0.3) ## stringr 1.4.0 2019-02-10 [1] RSPM (R 4.0.3) ## testthat 3.0.1 2023-03-10 [1] Github (R-lib/testthat@e99155a) ## usethis 1.6.3 2020-09-17 [1] RSPM (R 4.0.2) ## withr 2.3.0 2020-09-22 [1] RSPM (R 4.0.2) ## xfun 0.26 2023-03-10 [1] Github (yihui/xfun@74c2a66) ## yaml 2.2.1 2020-02-01 [1] RSPM (R 4.0.3) ## ## [1] /usr/local/lib/R/site-library ## [2] /usr/local/lib/R/library "],["references.html", "Chapter 13 References", " Chapter 13 References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
